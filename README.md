# E38_Fase_3

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

Fase 3 Avance de Proyecto, Gestion del Proyecto de Machine Learning

## Project Organization

```
â”œâ”€â”€ LICENSE                         <- Open-source license if one is chosen
â”œâ”€â”€ Makefile                        <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md                       <- The top-level README for developers using this project.
â”œâ”€â”€ params.yaml                     <- Centralized configuration file for pipeline parameters.
â”œâ”€â”€ data                
â”‚   â”œâ”€â”€ external                    <- Data from third party sources.
â”‚   â”œâ”€â”€ interim                     <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed                   <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw                         <- The original, immutable data dump.
â”‚               
â”œâ”€â”€ docs                            <- A default mkdocs project; see www.mkdocs.org for details
â”‚               
â”œâ”€â”€ models                          <- Trained and serialized models, model predictions, or model summaries
â”‚               
â”œâ”€â”€ notebooks                       <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                                      the creator's initials, and a short `-` delimited description, e.g.
â”‚                                      `1.0-jqp-initial-data-exploration`.
â”‚               
â”œâ”€â”€ pyproject.toml                  <- Project configuration file with package metadata for 
â”‚                                      MLFlow/DVC and configuration for tools like black
â”‚               
â”œâ”€â”€ references                      <- Data dictionaries, manuals, and all other explanatory materials.
â”‚               
â”œâ”€â”€ reports                         <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures                     <- Generated graphics and figures to be used in reporting
â”‚               
â”œâ”€â”€ requirements.txt                <- The requirements file for reproducing the analysis environment, e.g.
â”‚                                      generated with `pip freeze > requirements.txt`
â”‚               
â”œâ”€â”€ setup.cfg                       <- Configuration file for flake8
â”œâ”€â”€ dvc.yaml                        <- DVC pipeline definition
â”œâ”€â”€ dvc.lock                        <- Locked versions of DVC tracked files
â”‚               
â””â”€â”€ src                             <- Source code for the project
    â”œâ”€â”€ __init__.py                 <- Makes `src` a Python module
    â”œâ”€â”€ utils
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ cmd.py                  <- Helper functions to execute shell commands
    â”‚   â””â”€â”€ paths.py                <- Paths manager to create and ensure directories
    â”œâ”€â”€ config
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ dvc_setup.py            <- Functions to set dvc repos
    â”‚   â””â”€â”€ config.py               <- Store useful variables and configuration
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ clean_dataset.py        <- Script to clean raw data
    â”‚   â”œâ”€â”€ cleaning.py             <- Main cleaning scripts
    â”‚   â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”‚   â”œâ”€â”€ download_dataset.py     <- Scripts to fetch datasets from external sources
    â”‚   â”œâ”€â”€ features.py             <- Code to create features for modeling
    â”‚   â””â”€â”€ preprocess_data.py      <- Preprocessing pipelines for ML
    â””â”€â”€ modeling
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ plots_modeling.py       <- Plot logic to generate figures
        â”œâ”€â”€ plots.py                <- Code to create visualizations
        â”œâ”€â”€ predict_model.py        <- Model prediction logic and MLFlow integration
        â”œâ”€â”€ predict.py              <- Code to run model inference with trained models
        â”œâ”€â”€ train_model.py          <- Model training logic and MLFlow integration
        â””â”€â”€ train.py                <- Entry point to train models
```

--------

# Fase 2 | Avance de Proyecto
# Equipo 38

En esta actividad se continuarÃ¡ con el desarrollo del proyecto, dando seguimiento a los avances realizados en la Fase 1. Se mantendrÃ¡ la propuesta de valor, el anÃ¡lisis elaborado con el ML Canvas, asÃ­ como los datos, modelos y experimentos previamente desarrollados. El objetivo ahora es estructurar el proyecto de Machine Learning de forma profesional, aplicando buenas prÃ¡cticas como la refactorizaciÃ³n del cÃ³digo, el control de versiones, el seguimiento de experimentos, el registro de mÃ©tricas y modelos, y el aseguramiento de la reproducibilidad.

--------

## ðŸŽ¯ Objetivos

- Continuar con el desarrollo de proyectos de Machine Learning, a partir de los requerimientos, una propuesta de valor y un conjunto de datos preprocesados.
- Estructurar proyectos de Machine Learning de manera organizada (utilizando el template de Cookiecutter)
- Aplicar buenas prÃ¡cticas de codificaciÃ³n en cada etapa del pipeline y realizar RefactorizaciÃ³n del cÃ³digo.
- Registrar mÃ©tricas y aplicar control de versiones  a los experimentos utilizando herramientas de loging y tracking  (MLFlow/DVC)
- Visualizar y comparar resultados (mÃ©tricas) y gestionar el registro de los modelos (Data Registry MLFlow/DVC)

--------

## ðŸ‘¥ Roles del Equipo
| Integrante | MatrÃ­cula | Rol |
|---|---|---|
| Jaime Alejandro MendÃ­vil Altamirano| `A01253316` | SRE / DevOps |
| Christian Erick Mercado Flores | `A00841954` | Software Engineer  |
| Saul Mora Perea | `A01796295` | Data Engineer  |
| Juan Carlos PÃ©rez Nava | `A01795941` | Data Scientist  |
| Mario Javier Soriano Aguilera | `A01384282` | ML Engineer  |

--------

## ðŸ“¦ Instalar paqueterÃ­as
```bash
pip install -r requirements.txt --quiet
```
## ðŸ’¼ Clonar repositorio
```bash
git clone https://github.com/Jarcos09/MLops_E38_F2.git
cd MLops_E38_F2/
```

--------
ðŸ”§ RecomendaciÃ³n previa a la ejecuciÃ³n

Antes de ejecutar cualquier comando con make, asegÃºrate de:
- Estar ubicado en la carpeta raÃ­z del proyecto.
- Tener activado el ambiente virtual correspondiente.
Esto garantiza que las rutas, dependencias y configuraciones se interpreten correctamente durante la ejecuciÃ³n automatizada.


## ðŸ“š Makefile

Descargar Dataset:
```bash
make data
```

Realizar limpieza del Dataset:
```bash
make clean_data
```

Realizar FE:
```bash
make FE
```

Ejecuta (data â†’ clean_data â†’ FE):
```bash
make prepare
```

Ejecutar localmente servidor de MLFlow:
```bash
make mlflow-server
```

Inicia el servidor MLFLow:
```bash
make mlflow-start
```

Detiene el servidor MLFLow:
```bash
make mlflow-stop
```

Verifica si el servidor MLFLow estÃ¡ activo:
```bash
make mlflow-status
```

Realizar entrenamiento:
```bash
make train
```

Ejecuta (data â†’ clean_data â†’ FE â†’ train):
```bash
make all
```

Realizar preducciÃ³n:
```bash
make predict
```

ConfiguraciÃ³n completa de DVC GDRIVE remoto:
```bash
make dvc_gdrive_setup
```

ConfiguraciÃ³n completa de DVC AWS remoto:
```bash
make dvc_aws_setup
```

Ejecutar el pipeline completo de DVC (data â†’ clean â†’ FE â†’ train â†’ predict):
```bash
make dvc_repro
```

Subir los outputs del pipeline al remoto:
```bash
make dvc_push
```

Descargar los datos versionados del remoto:
```bash
make dvc_pull
```

Verificar quÃ© etapas del pipeline estÃ¡n desactualizadas:
```bash
make dvc_status
```

--------

## ðŸ§  MLflow

**MLflow** es una herramienta para gestionar el ciclo de vida de modelos de Machine Learning: rastrea experimentos, guarda mÃ©tricas y versiona modelos.

---

### Iniciar servidor local

Se puede utilizar el comando:
```bash
make dvc_setup
```

TambiÃ©n se puede ejecutar el servidor en modo local con SQLite y carpeta `mlruns`:
```bash
mlflow server \
    --backend-store-uri sqlite:///mlflow.db \
    --default-artifact-root ./mlruns \
    --host 0.0.0.0 \
    --port 5000
````

### Interfaz
http://localhost:5000

### IntegraciÃ³n en el Proyecto
* `train_model.py`: Registra mÃ©tricas, parÃ¡metros y modelos (Random Forest, XGBoost).

* `predict_model.py`: Usa modelos registrados para generar predicciones.

* `config/config.py`: Define la URI de tracking (mlflow_tracking_uri).

--------

## ðŸ’¾ DVC

### InicializaciÃ³n de Repositorio DVC

Se puede utilizar el comando:
```bash
make dvc_gdrive_setup
```
o

```bash
make dvc_aws_setup
```

TambiÃ©n, se puede inicializar manualmente de la siguiente manera:
```bash
dvc init
```
### GDRIVE
#### Agregar Repositorio DVC (GDrive)
```bash
dvc remote add -d data "$GDRIVE_REMOTE_URL"
```

#### ConfiguraciÃ³n de DVC (GDrive)
```bash
dvc remote modify data gdrive_client_id "$GDRIVE_CLIENT_ID"
dvc remote modify data gdrive_client_secret "$GDRIVE_CLIENT_SECRET"
```

### AWS
#### Agregar Repositorio DVC (AWS)
```bash
dvc remote add -d data "$AWS_REMOTE_URL"
```

#### ConfiguraciÃ³n de DVC (AWS)
```bash
dvc remote modify team_remote region "$AWS_REGION"
dvc remote modify team_remote profile "$AWS_PROFILE"
```

### Verificar Repositorios DVC Configurados
```bash
dvc remote list
```

### Repositorio DVC (GDrive)
[Carpeta Principal del Proyecto en Google Drive](https://drive.google.com/drive/u/2/folders/1VnjNYOpP2uSaaUtFdRzW45iwZJUbt-5v)

### Repositorio DVC (AWS)
Lista todos los objetos dentro de todos los subdirectorios:
```bash
aws s3 ls s3://itesm-mna/202502-equipo38 --recursive --profile equipo38 | head
``` 

--------

## ðŸ“Š Plots

### Generar plots

Ejemplo de histograma:
```bash
python -m src.modeling.plots --plot-type histogram --column X3 --filename x3_hist.png
```

Ejemplo de scatter plot:
```bash
python -m src.modeling.plots --plot-type scatter --x X1 --y Y1 --filename x1_y1_scatter.png
```

Ejemplo de correlation matrix:
```bash
python -m src.modeling.plots --plot-type correlation --filename corr_matrix.png
```

--------

## ðŸš€ Model serving (FastAPI)

Servicio HTTP para exponer el modelo entrenado.

---

### Endpoints

Se cuenta con `2` endpoints:
- ExaminaciÃ³n de operatividad: `GET /health`
- PredicciÃ³n: `POST /predict` (JSON)

#### Endpoint de predicciÃ³n
Esquema de entrada (JSON):

{
  "model_type": "xgb",
  "instances": [
    {"X1": 1.0, "X2": 2.0, "X3": 0.5},
    { ... }
  ]
}

Ejemplo de respuesta:

{
    "predictions": [
        {"prediction": 0.123},
        {"prediction": 0.456}
    ]
}

### EjecuciÃ³n del servicio localmente:

```bash
pip install -r requirements.txt
# Desde la raÃ­z del proyecto
# Si tu app estÃ¡ en `src.api.app` o `src.serving.app` ajusta el mÃ³dulo en consecuencia.
uvicorn src.api.app:app --host 0.0.0.0 --port 8000 --reload
```

###  Ejemplo request `curl`:

```bash
curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" \
  -d '{"model_type":"xgb","instances":[{"X1":0.98,"X2":514.5,"X3":294.0,"X4":110.25,"X5":7.0,"X6":2.0,"X7":0.0,"X8":0.0}]}'
```

### Ruta y versiÃ³n del artefacto del modelo

El proyecto registra modelos en MLflow y tambiÃ©n guarda un artefacto local. Se puede referenciar el artefacto usando dos formas:

- Ruta local (archivo): `models/rf_regressor.pkl` (configurado en `params.yaml`, propiedad `training.rf_model_file`).
- Registro MLflow (Model Registry): `models:/RFRegressor/<version>` (por ejemplo `models:/RFRegressor/1`).

---

## ðŸ“¦ Contenerizar la API (Docker)

Se provee un `Dockerfile` en la raÃ­z del proyecto para construir una imagen reproducible que incluya el servicio FastAPI y los artefactos del proyecto (incluyendo `models/` si lo deseas copiar dentro de la imagen).

1) Construir la imagen (ejemplo tag semÃ¡ntico):

```bash
docker build -t ml-service:latest .
# o versiÃ³n explÃ­cita
docker build -t cremercado/ml-service:1.0.0 .
```

2) Ejecutar localmente (mapea puerto 8000):

```bash
docker run --rm -p 8000:8000 cremercado/ml-service:1.0.0
```

3) Publicar en Docker Hub (pasos):

```bash
# 1) Taguear la imagen local con tu repo en Docker Hub
docker tag ml-service:latest cremercado/ml-service:1.0.0

# 2) Iniciar sesiÃ³n (te pedirÃ¡ usuario/contraseÃ±a)
docker login

# 3) Push
docker push cremercado/ml-service:1.0.0
```

Tagging / versioning policy recomendada:
- `cremercado/ml-service:1.0.0`  â€” versiÃ³n fijada por release
- `cremercado/ml-service:latest` â€” apuntar a la Ãºltima imagen publicada
- `cremercado/ml-service:staging` â€” para despliegues de pre-producciÃ³n